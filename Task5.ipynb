{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch实现L1，L2正则化以及Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1,了解知道Dropout原理 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  在机器学习的模型中，如果模型的参数太多，而训练样本又太少，训练出来的模型很容易产生过拟合的现象. 具体表现在：模型在训练数据上损失函数较小，预测准确率较高；但是在测试数据上损失函数比较大，预测准确率较低"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2012年，Hinton提出Dropout,用于防止过拟合. Dropout可以作为训练深度神经网络的一种trick. 在每个训练批次中，通过忽略一半的特征检测器（让一半的隐层节点值为0），可以明显地减少过拟合现象。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2,  用代码实现正则化(L1、L2、Dropout）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### https://www.jianshu.com/p/e53a608d3d75 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sigmoid = lambda x: 1 / (1 + np.exp(-x))\n",
    "layer_size = lambda x, y: (x.shape[0], 4, y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "initialize_parameters = lambda n_x, n_h, n_y: {\n",
    "    \"w1\": np.random.rand(n_h, n_x) * 0.01,\n",
    "    \"b1\": np.zeros((n_h, 1)),\n",
    "    \"w2\": np.random.rand(n_y, n_h) * 0.01,\n",
    "    \"b2\": np.zeros((n_y, 1))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = initialize_parameters(2,4,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'b1': array([[ 0.],\n",
       "        [ 0.],\n",
       "        [ 0.],\n",
       "        [ 0.]]), 'b2': array([[ 0.]]), 'w1': array([[ 0.00835272,  0.0019225 ],\n",
       "        [ 0.00395097,  0.00300081],\n",
       "        [ 0.00080104,  0.00904631],\n",
       "        [ 0.00370154,  0.00530697]]), 'w2': array([[ 0.00494116,  0.00132161,  0.00206454,  0.00076189]])}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def forward_propagetion_with_dropout(x, paramters, keep_prod=0.7):\n",
    "    # 取出参数\n",
    "    w1 = parameters['w1']\n",
    "    b1 = parameters['b1']\n",
    "    w2 = parameters['w2']\n",
    "    b2 = parameters['b2']\n",
    "    # 向前传播\n",
    "    z1 = np.matmul(w1, x) + b1\n",
    "    a1 = np.tanh(z1)\n",
    "    # 这里加入mask，使得其中一些神经元的活动变为0，在反向传播中，不再更新这些节点\n",
    "    mask1 = (np.random.rand(a1.shape[0], 1) < keep_prod)\n",
    "    \n",
    "    a1 = a1 * mask1\n",
    "    a1 = a1 / keep_prod\n",
    "    z2 = np.matmul(w2, a1) + b2\n",
    "    a2 = sigmoid(z2)\n",
    "    a2 = sigmoid(z2)\n",
    "    cache = {\n",
    "        \"z1\": z1,\n",
    "        \"a1\": a1,\n",
    "        \"mask1\": mask1,\n",
    "        \"z2\": z2,\n",
    "        \"a2\": a2\n",
    "    }\n",
    "    return a2, cache\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_cost(a2, y, parameters, lambd=0):\n",
    "    m = y.shape[1]\n",
    "    logprobs = (np.log(a2) * y) + np.log(1 - a2) * (1 - y)\n",
    "    cost = -np.sum(logprobs) / m\n",
    "    l2_loss = np.sum(np.square(parameters['w1'])) + np.sum(np.square(parameters['w2']))\n",
    "    cost = np.squeeze(cost)\n",
    "    return cost + lambd * l2_loss / (2 * m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def backward_propagetion_with_dropout(parameters, cache, x, y, lambd=0, keep_prob=0.7):\n",
    "    m = x.shape[1]\n",
    "    w1 = parameters['w1']\n",
    "    w2 = parameters['w2']\n",
    "    a1 = cache['a1']\n",
    "    a2 = cache['a2']\n",
    "    mask1 = cache['mask1']\n",
    "    \n",
    "    dz2 = a2 - y\n",
    "    dw2 = np.dot(dz2, a1.T) / m + lambd / m * w2\n",
    "    db2 = np.sum(dz2, axis=1, keepdims=True) / m\n",
    " \n",
    "    # Dropout的关键操作\n",
    "    da1 = np.dot(w2.T, dz2)\n",
    " \n",
    "    da1 = da1 * mask1\n",
    "    da1 = da1 / keep_prob\n",
    " \n",
    "    dz1 = np.multiply(np.dot(w2.T, dz2), (1 - np.power(a1, 2)))\n",
    "    dw1 = np.dot(dz1, x.T) / m + lambd / m * w1\n",
    "    db1 = np.sum(dz1, axis=1, keepdims=True) / m\n",
    " \n",
    "    grads = {\n",
    "        \"dw1\": dw1,\n",
    "        \"db1\": db1,\n",
    "        \"dw2\": dw2,\n",
    "        \"db2\": db2,\n",
    "    }\n",
    "    return grads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads, learning_rate=0.01):\n",
    "    w1 = parameters['w1']\n",
    "    b1 = parameters['b1']\n",
    "    w2 = parameters['w2']\n",
    "    b2 = parameters['b2']\n",
    " \n",
    "    dw1 = learning_rate * grads[\"dw1\"]\n",
    "    db1 = learning_rate * grads[\"db1\"]\n",
    "    dw2 = learning_rate * grads[\"dw2\"]\n",
    "    db2 = learning_rate * grads[\"db2\"]\n",
    " \n",
    "    w1 = w1 - dw1\n",
    "    b1 = b1 - db1\n",
    "    w2 = w2 - dw2\n",
    "    b2 = b2 - db2\n",
    " \n",
    "    parameters = {\n",
    "        \"w1\": w1,\n",
    "        \"b1\": b1,\n",
    "        \"w2\": w2,\n",
    "        \"b2\": b2\n",
    "    }\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "m = 200\n",
    "x = np.random.randn(2, m)\n",
    "y = (1 + (2 * (x[0, :] > 0) - 1) * (2 * (x[1, :] > 0) - 1)) / 2\n",
    "y = y.reshape(1, x.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.62434536e+00,  -6.11756414e-01,  -5.28171752e-01,\n",
       "         -1.07296862e+00,   8.65407629e-01,  -2.30153870e+00,\n",
       "          1.74481176e+00,  -7.61206901e-01,   3.19039096e-01,\n",
       "         -2.49370375e-01,   1.46210794e+00,  -2.06014071e+00,\n",
       "         -3.22417204e-01,  -3.84054355e-01,   1.13376944e+00,\n",
       "         -1.09989127e+00,  -1.72428208e-01,  -8.77858418e-01,\n",
       "          4.22137467e-02,   5.82815214e-01,  -1.10061918e+00,\n",
       "          1.14472371e+00,   9.01590721e-01,   5.02494339e-01,\n",
       "          9.00855949e-01,  -6.83727859e-01,  -1.22890226e-01,\n",
       "         -9.35769434e-01,  -2.67888080e-01,   5.30355467e-01,\n",
       "         -6.91660752e-01,  -3.96753527e-01,  -6.87172700e-01,\n",
       "         -8.45205641e-01,  -6.71246131e-01,  -1.26645989e-02,\n",
       "         -1.11731035e+00,   2.34415698e-01,   1.65980218e+00,\n",
       "          7.42044161e-01,  -1.91835552e-01,  -8.87628964e-01,\n",
       "         -7.47158294e-01,   1.69245460e+00,   5.08077548e-02,\n",
       "         -6.36995647e-01,   1.90915485e-01,   2.10025514e+00,\n",
       "          1.20158952e-01,   6.17203110e-01,   3.00170320e-01,\n",
       "         -3.52249846e-01,  -1.14251820e+00,  -3.49342722e-01,\n",
       "         -2.08894233e-01,   5.86623191e-01,   8.38983414e-01,\n",
       "          9.31102081e-01,   2.85587325e-01,   8.85141164e-01,\n",
       "         -7.54397941e-01,   1.25286816e+00,   5.12929820e-01,\n",
       "         -2.98092835e-01,   4.88518147e-01,  -7.55717130e-02,\n",
       "          1.13162939e+00,   1.51981682e+00,   2.18557541e+00,\n",
       "         -1.39649634e+00,  -1.44411381e+00,  -5.04465863e-01,\n",
       "          1.60037069e-01,   8.76168921e-01,   3.15634947e-01,\n",
       "         -2.02220122e+00,  -3.06204013e-01,   8.27974643e-01,\n",
       "          2.30094735e-01,   7.62011180e-01,  -2.22328143e-01,\n",
       "         -2.00758069e-01,   1.86561391e-01,   4.10051647e-01,\n",
       "          1.98299720e-01,   1.19008646e-01,  -6.70662286e-01,\n",
       "          3.77563786e-01,   1.21821271e-01,   1.12948391e+00,\n",
       "          1.19891788e+00,   1.85156417e-01,  -3.75284950e-01,\n",
       "         -6.38730407e-01,   4.23494354e-01,   7.73400683e-02,\n",
       "         -3.43853676e-01,   4.35968568e-02,  -6.20000844e-01,\n",
       "          6.98032034e-01,  -4.47128565e-01,   1.22450770e+00,\n",
       "          4.03491642e-01,   5.93578523e-01,  -1.09491185e+00,\n",
       "          1.69382433e-01,   7.40556451e-01,  -9.53700602e-01,\n",
       "         -2.66218506e-01,   3.26145467e-02,  -1.37311732e+00,\n",
       "          3.15159392e-01,   8.46160648e-01,  -8.59515941e-01,\n",
       "          3.50545979e-01,  -1.31228341e+00,  -3.86955093e-02,\n",
       "         -1.61577235e+00,   1.12141771e+00,   4.08900538e-01,\n",
       "         -2.46169559e-02,  -7.75161619e-01,   1.27375593e+00,\n",
       "          1.96710175e+00,  -1.85798186e+00,   1.23616403e+00,\n",
       "          1.62765075e+00,   3.38011697e-01,  -1.19926803e+00,\n",
       "          8.63345318e-01,  -1.80920302e-01,  -6.03920628e-01,\n",
       "         -1.23005814e+00,   5.50537496e-01,   7.92806866e-01,\n",
       "         -6.23530730e-01,   5.20576337e-01,  -1.14434139e+00,\n",
       "          8.01861032e-01,   4.65672984e-02,  -1.86569772e-01,\n",
       "         -1.01745873e-01,   8.68886157e-01,   7.50411640e-01,\n",
       "          5.29465324e-01,   1.37701210e-01,   7.78211279e-02,\n",
       "          6.18380262e-01,   2.32494559e-01,   6.82551407e-01,\n",
       "         -3.10116774e-01,  -2.43483776e+00,   1.03882460e+00,\n",
       "          2.18697965e+00,   4.41364444e-01,  -1.00155233e-01,\n",
       "         -1.36444744e-01,  -1.19054188e-01,   1.74094083e-02,\n",
       "         -1.12201873e+00,  -5.17094458e-01,  -9.97026828e-01,\n",
       "          2.48799161e-01,  -2.96641152e-01,   4.95211324e-01,\n",
       "         -1.74703160e-01,   9.86335188e-01,   2.13533901e-01,\n",
       "          2.19069973e+00,  -1.89636092e+00,  -6.46916688e-01,\n",
       "          9.01486892e-01,   2.52832571e+00,  -2.48634778e-01,\n",
       "          4.36689932e-02,  -2.26314243e-01,   1.33145711e+00,\n",
       "         -2.87307863e-01,   6.80069840e-01,  -3.19801599e-01,\n",
       "         -1.27255876e+00,   3.13547720e-01,   5.03184813e-01,\n",
       "          1.29322588e+00,  -1.10447026e-01,  -6.17362064e-01,\n",
       "          5.62761097e-01,   2.40737092e-01,   2.80665077e-01,\n",
       "         -7.31127037e-02,   1.16033857e+00,   3.69492716e-01,\n",
       "          1.90465871e+00,   1.11105670e+00,   6.59049796e-01,\n",
       "         -1.62743834e+00,   6.02319280e-01,   4.20282204e-01,\n",
       "          8.10951673e-01,   1.04444209e+00],\n",
       "       [ -4.00878192e-01,   8.24005618e-01,  -5.62305431e-01,\n",
       "          1.95487808e+00,  -1.33195167e+00,  -1.76068856e+00,\n",
       "         -1.65072127e+00,  -8.90555584e-01,  -1.11911540e+00,\n",
       "          1.95607890e+00,  -3.26499498e-01,  -1.34267579e+00,\n",
       "          1.11438298e+00,  -5.86523939e-01,  -1.23685338e+00,\n",
       "          8.75838928e-01,   6.23362177e-01,  -4.34956683e-01,\n",
       "          1.40754000e+00,   1.29101580e-01,   1.61694960e+00,\n",
       "          5.02740882e-01,   1.55880554e+00,   1.09402696e-01,\n",
       "         -1.21974440e+00,   2.44936865e+00,  -5.45774168e-01,\n",
       "         -1.98837863e-01,  -7.00398505e-01,  -2.03394449e-01,\n",
       "          2.42669441e-01,   2.01830179e-01,   6.61020288e-01,\n",
       "          1.79215821e+00,  -1.20464572e-01,  -1.23312074e+00,\n",
       "         -1.18231813e+00,  -6.65754518e-01,  -1.67419581e+00,\n",
       "          8.25029824e-01,  -4.98213564e-01,  -3.10984978e-01,\n",
       "         -1.89148284e-03,  -1.39662042e+00,  -8.61316361e-01,\n",
       "          6.74711526e-01,   6.18539131e-01,  -4.43171931e-01,\n",
       "          1.81053491e+00,  -1.30572692e+00,  -3.44987210e-01,\n",
       "         -2.30839743e-01,  -2.79308500e+00,   1.93752881e+00,\n",
       "          3.66332015e-01,  -1.04458938e+00,   2.05117344e+00,\n",
       "          5.85662000e-01,   4.29526140e-01,  -6.06998398e-01,\n",
       "          1.06222724e-01,  -1.52568032e+00,   7.95026094e-01,\n",
       "         -3.74438319e-01,   1.34048197e-01,   1.20205486e+00,\n",
       "          2.84748111e-01,   2.62467445e-01,   2.76499305e-01,\n",
       "         -7.33271604e-01,   8.36004719e-01,   1.54335911e+00,\n",
       "          7.58805660e-01,   8.84908814e-01,  -8.77281519e-01,\n",
       "         -8.67787223e-01,  -1.44087602e+00,   1.23225307e+00,\n",
       "         -2.54179868e-01,   1.39984394e+00,  -7.81911683e-01,\n",
       "         -4.37508983e-01,   9.54250872e-02,   9.21450069e-01,\n",
       "          6.07501958e-02,   2.11124755e-01,   1.65275673e-02,\n",
       "          1.77187720e-01,  -1.11647002e+00,   8.09271010e-02,\n",
       "         -1.86578994e-01,  -5.68244809e-02,   4.92336556e-01,\n",
       "         -6.80678141e-01,  -8.45080274e-02,  -2.97361883e-01,\n",
       "          4.17302005e-01,   7.84770651e-01,  -9.55425262e-01,\n",
       "          5.85910431e-01,   2.06578332e+00,  -1.47115693e+00,\n",
       "         -8.30171895e-01,  -8.80577600e-01,  -2.79097722e-01,\n",
       "          1.62284909e+00,   1.33526763e-02,  -6.94693595e-01,\n",
       "          6.21803504e-01,  -5.99804531e-01,   1.12341216e+00,\n",
       "          3.05267040e-01,   1.38877940e+00,  -6.61344243e-01,\n",
       "          3.03085711e+00,   8.24584625e-01,   6.54580153e-01,\n",
       "         -5.11884476e-02,  -7.25597119e-01,  -8.67768678e-01,\n",
       "         -1.35977326e-01,  -7.97269785e-01,   2.82675712e-01,\n",
       "         -8.26097432e-01,   6.21082701e-01,   9.56121704e-01,\n",
       "         -7.05840507e-01,   1.19268607e+00,  -2.37941936e-01,\n",
       "          1.15528789e+00,   4.38166347e-01,   1.12232832e+00,\n",
       "         -9.97019796e-01,  -1.06793987e-01,   1.45142926e+00,\n",
       "         -6.18036848e-01,  -2.03720123e+00,  -1.94258918e+00,\n",
       "         -2.50644065e+00,  -2.11416392e+00,  -4.11639163e-01,\n",
       "          1.27852808e+00,  -4.42229280e-01,   3.23527354e-01,\n",
       "         -1.09991490e-01,   8.54894544e-03,  -1.68198840e-01,\n",
       "         -1.74180344e-01,   4.61164100e-01,  -1.17598267e+00,\n",
       "          1.01012718e+00,   9.20017933e-01,  -1.95057341e-01,\n",
       "          8.05393424e-01,  -7.01344426e-01,  -5.37223024e-01,\n",
       "          1.56263850e-01,  -1.90221025e-01,  -4.48738033e-01,\n",
       "         -6.72448039e-01,  -5.57494722e-01,   9.39168744e-01,\n",
       "         -1.94332341e+00,   3.52494364e-01,  -2.36436952e-01,\n",
       "          7.27813500e-01,   5.15073614e-01,  -2.78253447e+00,\n",
       "          5.84646610e-01,   3.24274243e-01,   2.18628366e-02,\n",
       "         -4.68673816e-01,   8.53281222e-01,  -4.13029310e-01,\n",
       "          1.83471763e+00,   5.64382855e-01,   2.13782807e+00,\n",
       "         -7.85533997e-01,  -1.75592564e+00,   7.14789597e-01,\n",
       "          8.52704062e-01,   3.53600971e-02,  -1.53879325e+00,\n",
       "         -4.47895185e-01,   6.17985534e-01,  -1.84176326e-01,\n",
       "         -1.15985185e-01,  -1.75458969e-01,  -9.33914656e-01,\n",
       "         -5.33020326e-01,  -1.42655542e+00,   1.76795995e+00,\n",
       "         -4.75372875e-01,   4.77610182e-01,  -1.02188594e+00,\n",
       "          7.94528240e-01,  -1.87316098e+00,   9.20615118e-01,\n",
       "         -3.53679249e-02,   2.11060505e+00]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  1.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,  1.,  0.,\n",
       "         1.,  0.,  0.,  0.,  1.,  1.,  1.,  0.,  1.,  1.,  1.,  0.,  0.,\n",
       "         1.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,  1.,  0.,  0.,\n",
       "         1.,  1.,  1.,  1.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,  1.,\n",
       "         1.,  0.,  0.,  0.,  1.,  1.,  1.,  0.,  0.,  0.,  1.,  1.,  1.,\n",
       "         0.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  0.,  1.,  1.,  1.,\n",
       "         0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  1.,  0.,  1.,  0.,\n",
       "         0.,  0.,  1.,  0.,  0.,  0.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,\n",
       "         1.,  1.,  1.,  1.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,  0.,  0.,\n",
       "         1.,  0.,  0.,  1.,  1.,  1.,  0.,  0.,  1.,  0.,  1.,  1.,  1.,\n",
       "         0.,  0.,  1.,  0.,  1.,  1.,  0.,  1.,  0.,  0.,  1.,  0.,  0.,\n",
       "         1.,  0.,  1.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.,  1.,\n",
       "         0.,  1.,  0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  1.,\n",
       "         0.,  0.,  0.,  1.,  1.,  1.,  0.,  1.,  1.,  0.,  0.,  0.,  1.,\n",
       "         0.,  0.,  0.,  1.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,\n",
       "         0.,  0.,  1.,  0.,  1.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_iterations = 10\n",
    "learning_rate = 0.1\n",
    "n_x, n_h, n_y = 2, 30, 1\n",
    "costs = []\n",
    "keep_prob = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = initialize_parameters(n_x, n_h, n_y)\n",
    "w1 = parameters['w1']\n",
    "b1 = parameters['b1']\n",
    "w2 = parameters['w2']\n",
    "b2 = parameters['b2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0:0.693123\n",
      "Cost after iteration 1:0.693079\n",
      "Cost after iteration 2:0.693048\n",
      "Cost after iteration 3:0.693010\n",
      "Cost after iteration 4:0.692978\n",
      "Cost after iteration 5:0.692937\n",
      "Cost after iteration 6:0.692903\n",
      "Cost after iteration 7:0.692873\n",
      "Cost after iteration 8:0.692840\n",
      "Cost after iteration 9:0.692827\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_iterations):\n",
    "    a2, cache = forward_propagetion_with_dropout(x, parameters)\n",
    "    cost = compute_cost(a2, y, parameters)\n",
    "    grads = backward_propagetion_with_dropout(parameters, cache, x, y)\n",
    "    # 关键步骤，参数更新\n",
    "    parameters = update_parameters(parameters, grads, learning_rate)\n",
    " \n",
    "    if i % 1 == 0:\n",
    "        print(\"Cost after iteration %i:%f\" % (i, cost))\n",
    "        costs.append(cost)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3,  pytorch实现dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-df06bec45e42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.l1 = nn.Linear(8, 60)\n",
    "        self.l2 = nn.Linear(60, 4)\n",
    "        self.l3 = nn.Linear(4, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        # 直接调用torch.nn.Dropout\n",
    "        self.dropout = nn.Dropout(p=0.4)\n",
    " \n",
    "    def foward(self, x):\n",
    "        out1 = self.sigmoid(self.l1(x))\n",
    "        out2 = self.dropout(out1)\n",
    "        out3 = self.sigmoid(self.l2(out2))\n",
    "        y_pred = self.sigmoid(self.l3(out3))\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
